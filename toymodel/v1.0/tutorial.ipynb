{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2551005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from model import create_toy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f59434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 101\n",
      "One-hot helper ready\n"
     ]
    }
   ],
   "source": [
    "# 1) Load vocab and build one-hot tools\n",
    "vocab_path = \"vocab_chars.json\"\n",
    "with open(vocab_path, 'r') as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "\n",
    "# helper: smiles -> one-hot [seq_len, vocab_size]\n",
    "def smiles_to_onehot(smiles: str, vocab: dict, max_len: int = 50):\n",
    "    one_hot = np.zeros((max_len, vocab_size), dtype=np.float32)\n",
    "    for i, ch in enumerate(smiles[:max_len]):\n",
    "        idx = vocab.get(ch, vocab.get('<unk>', 3))\n",
    "        one_hot[i, idx] = 1.0\n",
    "    # pad remainder with <pad>\n",
    "    pad_id = vocab.get('<pad>', 0)\n",
    "    for i in range(len(smiles), max_len):\n",
    "        one_hot[i, pad_id] = 1.0\n",
    "    return one_hot\n",
    "\n",
    "print(\"One-hot helper ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ab10ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([1, 50, 101])\n",
      "Output: torch.Size([1, 1]) 0.7667984366416931\n"
     ]
    }
   ],
   "source": [
    "# 2) Create model and run a quick forward\n",
    "model = create_toy_model(vocab_size=vocab_size)\n",
    "model.eval()\n",
    "\n",
    "seq_len = 50\n",
    "smiles = \"CC[NH+](CC)[C@](C)(CC)[C@H](O)c1cscc1Br\"\n",
    "one_hot = smiles_to_onehot(smiles, vocab, max_len=seq_len)\n",
    "input_tensor = torch.from_numpy(one_hot).unsqueeze(0)  # [1, seq_len, vocab_size]\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(input_tensor)\n",
    "\n",
    "print(\"Input:\", input_tensor.shape)\n",
    "print(\"Output:\", out.shape, out.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edf968b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TorchScript: smiles_transformer_regression.pt\n",
      "Saved example input: example_input.npy (1, 50, 101)\n"
     ]
    }
   ],
   "source": [
    "# 3) Export TorchScript (.pt)\n",
    "dummy = torch.zeros(1, seq_len, vocab_size, dtype=torch.float32)\n",
    "traced = torch.jit.trace(model, dummy, strict=False, check_trace=False)\n",
    "traced_path = \"smiles_transformer_regression.pt\"\n",
    "traced.save(traced_path)\n",
    "print(\"Saved TorchScript:\", traced_path)\n",
    "\n",
    "# 4) Save example input (.npy)\n",
    "example_path = \"example_input.npy\"\n",
    "np.save(example_path, input_tensor.numpy())\n",
    "print(\"Saved example input:\", example_path, input_tensor.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9306f485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9063a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b4fb5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f42b17a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
