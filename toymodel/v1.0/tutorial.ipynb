{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2551005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from model import create_toy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f59434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 101\n"
     ]
    }
   ],
   "source": [
    "# 1) Load vocab and build one-hot tools\n",
    "vocab_path = \"vocab_chars.json\"\n",
    "with open(vocab_path, 'r') as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "\n",
    "# smiles -> one-hot [seq_len, vocab_size]\n",
    "def smiles_to_onehot(smiles: str, vocab: dict, max_len: int = 50):\n",
    "    one_hot = np.zeros((max_len, vocab_size), dtype=np.float32)\n",
    "    for i, ch in enumerate(smiles[:max_len]):\n",
    "        idx = vocab.get(ch, vocab.get('<unk>', 3))\n",
    "        one_hot[i, idx] = 1.0\n",
    "    # pad remainder with <pad>\n",
    "    pad_id = vocab.get('<pad>', 0)\n",
    "    for i in range(len(smiles), max_len):\n",
    "        one_hot[i, pad_id] = 1.0\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ab10ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([1, 50, 101])\n",
      "Output: torch.Size([1, 1]) 0.20094776153564453\n"
     ]
    }
   ],
   "source": [
    "# 2) Create model and run a quick forward\n",
    "model = create_toy_model(vocab_size=vocab_size)\n",
    "model.eval()\n",
    "\n",
    "seq_len = 50\n",
    "smiles = \"CC[NH+](CC)[C@](C)(CC)[C@H](O)c1cscc1Br\"\n",
    "one_hot = smiles_to_onehot(smiles, vocab, max_len=seq_len)\n",
    "input_tensor = torch.from_numpy(one_hot).unsqueeze(0)  # [1, seq_len, vocab_size]\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(input_tensor)\n",
    "\n",
    "print(\"Input:\", input_tensor.shape)\n",
    "print(\"Output:\", out.shape, out.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edf968b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Export TorchScript (.pt)\n",
    "dummy = torch.zeros(1, seq_len, vocab_size, dtype=torch.float32)\n",
    "traced = torch.jit.trace(model, dummy, strict=False, check_trace=False)\n",
    "traced_path = \"smiles_transformer_regression.pt\"\n",
    "traced.save(traced_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e01bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved example input: example_input.npy (1, 50, 101)\n"
     ]
    }
   ],
   "source": [
    "# 4) Save example input (.npy)\n",
    "example_path = \"example_input.npy\"\n",
    "np.save(example_path, input_tensor.numpy())\n",
    "print(\"Saved example input:\", example_path, input_tensor.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d576fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton config info:\n",
      "{'name': 'smiles_transformer_regression', 'platform': 'pytorch_libtorch', 'max_batch_size': 8, 'input': {'name': 'input__0', 'dtype': 'TYPE_FP32', 'dims': [50, 101]}, 'output': {'name': 'output__0', 'dtype': 'TYPE_FP32', 'dims': [1]}}\n"
     ]
    }
   ],
   "source": [
    "# 5) Print Triton config info and save config.pbtxt\n",
    "model_name = \"smiles_transformer_regression\"\n",
    "platform = \"pytorch_libtorch\"\n",
    "max_batch_size = 8\n",
    "input_name = \"input__0\"\n",
    "output_name = \"output__0\"\n",
    "\n",
    "# Gather shapes from prior cells\n",
    "seq_len = int(seq_len)\n",
    "vocab_size = int(vocab_size)\n",
    "input_dims = [seq_len, vocab_size]\n",
    "output_dims = [1]\n",
    "\n",
    "print(\"Triton config info:\")\n",
    "print({\n",
    "    \"name\": model_name,\n",
    "    \"platform\": platform,\n",
    "    \"max_batch_size\": max_batch_size,\n",
    "    \"input\": {\"name\": input_name, \"dtype\": \"TYPE_FP32\", \"dims\": input_dims},\n",
    "    \"output\": {\"name\": output_name, \"dtype\": \"TYPE_FP32\", \"dims\": output_dims},\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9306f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_content = f\"\"\"name: \\\"{model_name}\\\"\n",
    "platform: \\\"{platform}\\\"\n",
    "max_batch_size: {max_batch_size}\n",
    "\n",
    "input [\n",
    "  {{\n",
    "    name: \\\"{input_name}\\\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [{input_dims[0]}, {input_dims[1]}]\n",
    "  }}\n",
    "]\n",
    "\n",
    "output [\n",
    "  {{\n",
    "    name: \\\"{output_name}\\\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [{output_dims[0]}]\n",
    "  }}\n",
    "]\n",
    "\n",
    "instance_group [\n",
    "  {{\n",
    "    count: 1\n",
    "    kind: KIND_CPU\n",
    "  }}\n",
    "]\n",
    "\n",
    "dynamic_batching {{\n",
    "  preferred_batch_size: [1, 2, 4, 8]\n",
    "  max_queue_delay_microseconds: 100\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9063a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved config.pbtxt: config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "# Save config.pbtxt one level up so it matches Triton model repo layout\n",
    "config_path = os.path.join(\"config.pbtxt\")\n",
    "with open(config_path, \"w\") as f:\n",
    "    f.write(config_content)\n",
    "print(\"Saved config.pbtxt:\", config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b4fb5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f42b17a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
